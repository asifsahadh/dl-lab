{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f37da7d",
   "metadata": {},
   "source": [
    "### __ResNet vs DenseNet Assignment | Mohammed Asif Sahadh - 24MSD7061__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ebfee",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333d90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0394c2f",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163b55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANGRY\n",
    "train_angry_dir = r\"emotion\\1. train\\angry\"\n",
    "train_angry_imgs = []\n",
    "for img in os.listdir(train_angry_dir):\n",
    "    img_path = os.path.join(train_angry_dir, img)\n",
    "    train_angry_img = Image.open(img_path, 'r')\n",
    "    train_angry_imgs.append(train_angry_img)\n",
    "train_angry_data = np.array(train_angry_imgs)\n",
    "\n",
    "# DISGUISTED\n",
    "train_disgusted_dir = r\"emotion\\1. train\\disgusted\"\n",
    "train_disgusted_imgs = []\n",
    "for img in os.listdir(train_disgusted_dir):\n",
    "    img_path = os.path.join(train_disgusted_dir, img)\n",
    "    train_disgusted_img = Image.open(img_path, 'r')\n",
    "    train_disgusted_imgs.append(train_disgusted_img)\n",
    "train_disgusted_data = np.array(train_disgusted_imgs)\n",
    "\n",
    "# FEARFUL\n",
    "train_fearful_dir = r\"emotion\\1. train\\fearful\"\n",
    "train_fearful_imgs = []\n",
    "for img in os.listdir(train_fearful_dir):\n",
    "    img_path = os.path.join(train_fearful_dir, img)\n",
    "    train_fearful_img = Image.open(img_path, 'r')\n",
    "    train_fearful_imgs.append(train_fearful_img)\n",
    "train_fearful_data = np.array(train_fearful_imgs)\n",
    "\n",
    "# HAPPY\n",
    "train_happy_dir = r\"emotion\\1. train\\happy\"\n",
    "train_happy_imgs = []\n",
    "for img in os.listdir(train_happy_dir):\n",
    "    img_path = os.path.join(train_happy_dir, img)\n",
    "    train_happy_img = Image.open(img_path, 'r')\n",
    "    train_happy_imgs.append(train_happy_img)\n",
    "train_happy_data = np.array(train_happy_imgs)\n",
    "\n",
    "# NEUTRAL\n",
    "train_neutral_dir = r\"emotion\\1. train\\neutral\"\n",
    "train_neutral_imgs = []\n",
    "for img in os.listdir(train_neutral_dir):\n",
    "    img_path = os.path.join(train_neutral_dir, img)\n",
    "    train_neutral_img = Image.open(img_path, 'r')\n",
    "    train_neutral_imgs.append(train_neutral_img)\n",
    "train_neutral_data = np.array(train_neutral_imgs)\n",
    "\n",
    "# SAD\n",
    "train_sad_dir = r\"emotion\\1. train\\sad\"\n",
    "train_sad_imgs = []\n",
    "for img in os.listdir(train_sad_dir):\n",
    "    img_path = os.path.join(train_sad_dir, img)\n",
    "    train_sad_img = Image.open(img_path, 'r')\n",
    "    train_sad_imgs.append(train_sad_img)\n",
    "train_sad_data = np.array(train_sad_imgs)\n",
    "\n",
    "# SURPRISED\n",
    "train_surprised_dir = r\"emotion\\1. train\\surprised\"\n",
    "train_surprised_imgs = []\n",
    "for img in os.listdir(train_surprised_dir):\n",
    "    img_path = os.path.join(train_surprised_dir, img)\n",
    "    train_surprised_img = Image.open(img_path, 'r')\n",
    "    train_surprised_imgs.append(train_surprised_img)\n",
    "train_surprised_data = np.array(train_surprised_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13820ece",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9bdf44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANGRY\n",
    "test_angry_dir = r\"emotion\\2. test\\angry\"\n",
    "test_angry_imgs = []\n",
    "for img in os.listdir(test_angry_dir):\n",
    "    img_path = os.path.join(test_angry_dir, img)\n",
    "    test_angry_img = Image.open(img_path, 'r')\n",
    "    test_angry_imgs.append(test_angry_img)\n",
    "test_angry_data = np.array(test_angry_imgs)\n",
    "\n",
    "# DISGUISTED\n",
    "test_disgusted_dir = r\"emotion\\2. test\\disgusted\"\n",
    "test_disgusted_imgs = []\n",
    "for img in os.listdir(test_disgusted_dir):\n",
    "    img_path = os.path.join(test_disgusted_dir, img)\n",
    "    test_disgusted_img = Image.open(img_path, 'r')\n",
    "    test_disgusted_imgs.append(test_disgusted_img)\n",
    "test_disgusted_data = np.array(test_disgusted_imgs)\n",
    "\n",
    "# FEARFUL\n",
    "test_fearful_dir = r\"emotion\\2. test\\fearful\"\n",
    "test_fearful_imgs = []\n",
    "for img in os.listdir(test_fearful_dir):\n",
    "    img_path = os.path.join(test_fearful_dir, img)\n",
    "    test_fearful_img = Image.open(img_path, 'r')\n",
    "    test_fearful_imgs.append(test_fearful_img)\n",
    "test_fearful_data = np.array(test_fearful_imgs)\n",
    "\n",
    "# HAPPY\n",
    "test_happy_dir = r\"emotion\\2. test\\happy\"\n",
    "test_happy_imgs = []\n",
    "for img in os.listdir(test_happy_dir):\n",
    "    img_path = os.path.join(test_happy_dir, img)\n",
    "    test_happy_img = Image.open(img_path, 'r')\n",
    "    test_happy_imgs.append(test_happy_img)\n",
    "test_happy_data = np.array(test_happy_imgs)\n",
    "\n",
    "# NEUTRAL\n",
    "test_neutral_dir = r\"emotion\\2. test\\neutral\"\n",
    "test_neutral_imgs = []\n",
    "for img in os.listdir(test_neutral_dir):\n",
    "    img_path = os.path.join(test_neutral_dir, img)\n",
    "    test_neutral_img = Image.open(img_path, 'r')\n",
    "    test_neutral_imgs.append(test_neutral_img)\n",
    "test_neutral_data = np.array(test_neutral_imgs)\n",
    "\n",
    "# SAD\n",
    "test_sad_dir = r\"emotion\\2. test\\sad\"\n",
    "test_sad_imgs = []\n",
    "for img in os.listdir(test_sad_dir):\n",
    "    img_path = os.path.join(test_sad_dir, img)\n",
    "    test_sad_img = Image.open(img_path, 'r')\n",
    "    test_sad_imgs.append(test_sad_img)\n",
    "test_sad_data = np.array(test_sad_imgs)\n",
    "\n",
    "# SURPRISED\n",
    "test_surprised_dir = r\"emotion\\2. test\\surprised\"\n",
    "test_surprised_imgs = []\n",
    "for img in os.listdir(test_surprised_dir):\n",
    "    img_path = os.path.join(test_surprised_dir, img)\n",
    "    test_surprised_img = Image.open(img_path, 'r')\n",
    "    test_surprised_imgs.append(test_surprised_img)\n",
    "test_surprised_data = np.array(test_surprised_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7efc6",
   "metadata": {},
   "source": [
    "#### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd932bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((train_angry_data, train_disgusted_data, train_fearful_data, train_happy_data, train_neutral_data, train_sad_data, train_surprised_data), axis = 0)\n",
    "X_test = np.concatenate((test_angry_data, test_disgusted_data, test_fearful_data, test_happy_data, test_neutral_data, test_sad_data, test_surprised_data), axis = 0)\n",
    "\n",
    "\n",
    "all_data = np.concatenate([X_train, X_test])\n",
    "mean = all_data.mean()\n",
    "std = all_data.std()\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e425398",
   "metadata": {},
   "source": [
    "_Let Pandas be 0 & Bears be 1._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986b3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab_angry = np.zeros(train_angry_data.shape[0])           # Label 0\n",
    "train_lab_disgusted = np.ones(train_disgusted_data.shape[0])    # Label 1\n",
    "train_lab_fearful = np.full(train_fearful_data.shape[0], 2)     # Label 2\n",
    "train_lab_happy = np.full(train_happy_data.shape[0], 3)         # Label 3\n",
    "train_lab_neutral = np.full(train_neutral_data.shape[0], 4)     # Label 4\n",
    "train_lab_sad = np.full(train_sad_data.shape[0], 5)             # Label 5\n",
    "train_lab_surprised = np.full(train_surprised_data.shape[0], 6) # Label 6\n",
    "\n",
    "test_lab_angry = np.zeros(test_angry_data.shape[0])           \n",
    "test_lab_disgusted = np.ones(test_disgusted_data.shape[0])    \n",
    "test_lab_fearful = np.full(test_fearful_data.shape[0], 2)     \n",
    "test_lab_happy = np.full(test_happy_data.shape[0], 3)         \n",
    "test_lab_neutral = np.full(test_neutral_data.shape[0], 4)     \n",
    "test_lab_sad = np.full(test_sad_data.shape[0], 5)             \n",
    "test_lab_surprised = np.full(test_surprised_data.shape[0], 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe36918",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((train_lab_angry, train_lab_disgusted, train_lab_fearful, train_lab_happy, train_lab_neutral, train_lab_sad, train_lab_surprised), axis = 0)\n",
    "y_test = np.concatenate((test_lab_angry, test_lab_disgusted, test_lab_fearful, train_lab_happy, train_lab_neutral, train_lab_sad, train_lab_surprised), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00046b61",
   "metadata": {},
   "source": [
    "#### Get GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ea8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed517542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c35963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9345af7",
   "metadata": {},
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ccf3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "def shuffle(X, y):\n",
    "    indices = torch.randperm(X.size(0))\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73e6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.permute(0, 3, 1, 2)\n",
    "# X_test = X_test.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71238f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([28709, 48, 48])\n",
      "Testing data shape: torch.Size([7178, 48, 48])\n",
      "\n",
      "Training labels shape: torch.Size([28709])\n",
      "Testing labels shape: torch.Size([7178])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print()\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673d781",
   "metadata": {},
   "source": [
    "#### Model definitions & stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97ab3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce9fa10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(3, 32, kernel_size = 3, padding = 1)  \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        self.fc1 = nn.Linear(32 * 128 * 128, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.dropout((F.relu(self.conv(x)))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return x\n",
    "\n",
    "cnn = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d7507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f304c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53551a3d",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0376edb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 16, 48, 48] to have 3 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m batch_labels = batch_labels.to(device).long()\n\u001b[32m     20\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m outputs = \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m loss = criterion(outputs, batch_labels)\n\u001b[32m     25\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\dl-lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\dl-lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.pool(\u001b[38;5;28mself\u001b[39m.dropout((F.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))))\n\u001b[32m     15\u001b[39m     x = torch.flatten(x, \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.fc1(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\dl-lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\dl-lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\dl-lab\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asifs\\anaconda3\\envs\\dl-lab\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 16, 48, 48] to have 3 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    indices = torch.randperm(X_train.size(0))\n",
    "    X_train_shuffled = X_train[indices]\n",
    "    y_train_shuffled = y_train[indices]\n",
    "\n",
    "    cnn.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_data = X_train_shuffled[i:i + batch_size]  \n",
    "        batch_labels = y_train_shuffled[i:i + batch_size]\n",
    "\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = cnn(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    num_batches = (len(X_train) + batch_size - 1) // batch_size\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / num_batches:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0fdb716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy: 99.8\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_data = X_train[i:i + batch_size]\n",
    "        batch_labels = y_train[i:i + batch_size]\n",
    "        \n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device).long()\n",
    "        \n",
    "        outputs = cnn(batch_data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(f\"Training accuracy: {100 * correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25e03e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test), batch_size):\n",
    "        batch_data = X_test[i:i + batch_size]\n",
    "        batch_labels = y_test[i:i + batch_size]\n",
    "        \n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device).long()\n",
    "        \n",
    "        outputs = cnn(batch_data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "print()\n",
    "print(f\"Testing accuracy: {100 * correct / total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdfae4",
   "metadata": {},
   "source": [
    "#### Final Metrics\n",
    "Training accuracy: 99.8%<br>\n",
    "Testing accuracy: 100%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
