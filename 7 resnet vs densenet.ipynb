{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed6cab2",
   "metadata": {},
   "source": [
    "### __Resnet vs Densenet Assignment | Mohammed Asif Sahadh - 24MSD7061__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ee415",
   "metadata": {},
   "source": [
    "#### Load Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62732b61",
   "metadata": {},
   "source": [
    "#### Change output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c43d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c60a8",
   "metadata": {},
   "source": [
    "#### Data loading & processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2138552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder('face/train', transform = transform)\n",
    "val_dataset = ImageFolder('face/val', transform = transform)\n",
    "test_dataset = ImageFolder('face/test', transform = transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406d0e5",
   "metadata": {},
   "source": [
    "#### Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351e9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr = 0.01, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1082299",
   "metadata": {},
   "source": [
    "#### Define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f9af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}...\")\n",
    "        # set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # reset the gradients to zero before the backward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward pass: compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.float() / len(train_loader.dataset)\n",
    "\n",
    "        # set the model to evaluation mode for validation\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # disable gradient computation for validation (saves memory and computations)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward pass: compute the model output\n",
    "                outputs = model(inputs)\n",
    "                # get the predicted class (with the highest score)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                # compute the loss between the predictions and actual labels\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_acc = running_corrects.float() / len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1794d33",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7290dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "Epoch [1/5], train loss: 1.3128, train acc: 0.5381, val loss: 2.0901, val acc: 0.4042\n",
      "Epoch 2...\n",
      "Epoch [2/5], train loss: 1.2426, train acc: 0.5582, val loss: 2.9313, val acc: 0.3521\n",
      "Epoch 3...\n",
      "Epoch [3/5], train loss: 1.2661, train acc: 0.5592, val loss: 2.6361, val acc: 0.3604\n",
      "Epoch 4...\n",
      "Epoch [4/5], train loss: 1.2846, train acc: 0.5620, val loss: 2.0494, val acc: 0.4271\n",
      "Epoch 5...\n",
      "Epoch [5/5], train loss: 1.2571, train acc: 0.5716, val loss: 2.1428, val acc: 0.4083\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8bc7",
   "metadata": {},
   "source": [
    "#### Repeat the same steps for Densenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f136407",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6abc0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "model.fc = torch.nn.Linear(model.classifier.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a96e3473",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr = 0.01, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6b6b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}...\")\n",
    "        # set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # reset the gradients to zero before the backward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward pass: compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.float() / len(train_loader.dataset)\n",
    "\n",
    "        # set the model to evaluation mode for validation\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # disable gradient computation for validation (saves memory and computations)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward pass: compute the model output\n",
    "                outputs = model(inputs)\n",
    "                # get the predicted class (with the highest score)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                # compute the loss between the predictions and actual labels\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_acc = running_corrects.float() / len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "811f80ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "Epoch [1/5], train loss: 1.5069, train acc: 0.5029, val loss: 2.3069, val acc: 0.3771\n",
      "Epoch 2...\n",
      "Epoch [2/5], train loss: 1.2712, train acc: 0.5590, val loss: 2.1925, val acc: 0.4354\n",
      "Epoch 3...\n",
      "Epoch [3/5], train loss: 1.2629, train acc: 0.5696, val loss: 1.7259, val acc: 0.4625\n",
      "Epoch 4...\n",
      "Epoch [4/5], train loss: 1.2126, train acc: 0.5792, val loss: 1.9870, val acc: 0.4479\n",
      "Epoch 5...\n",
      "Epoch [5/5], train loss: 1.3152, train acc: 0.5726, val loss: 2.3747, val acc: 0.4021\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
