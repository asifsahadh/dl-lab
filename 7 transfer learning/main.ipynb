{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7366aee7",
   "metadata": {},
   "source": [
    "### __Transfer Learning Assignment | Mohammed Asif Sahadh - 24MSD7061__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8db092",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240fb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63d5b4",
   "metadata": {},
   "source": [
    "#### Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc552b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cffc6e",
   "metadata": {},
   "source": [
    "#### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c437a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd81bf0",
   "metadata": {},
   "source": [
    "#### Data transformation to match pretrained model training data dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e253f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2009375",
   "metadata": {},
   "source": [
    "#### Get data & load it to PyTorch DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58f9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = r\"train\"\n",
    "test_data_path = r\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d01a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transform['train'])\n",
    "train_data_loader = data.DataLoader(train_data, batch_size = batch_size, shuffle = True,  num_workers = 4)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root = test_data_path, transform = data_transform['test'])\n",
    "test_data_loader = data.DataLoader(test_data, batch_size = batch_size, shuffle = True,  num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ef251",
   "metadata": {},
   "source": [
    "#### Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c022e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights = 'DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a48a5",
   "metadata": {},
   "source": [
    "#### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a6cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120856f",
   "metadata": {},
   "source": [
    "#### 1. __Fine Tune Fully Connected Layers Only__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fdbc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d90042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes) # modify output neurons\n",
    "model.cuda() # send model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f8b9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3060\n",
      "Epoch 20/100, Loss: 0.1177\n",
      "Epoch 30/100, Loss: 0.0485\n",
      "Epoch 40/100, Loss: 0.0441\n",
      "Epoch 50/100, Loss: 0.0154\n",
      "Epoch 60/100, Loss: 0.0082\n",
      "Epoch 70/100, Loss: 0.0077\n",
      "Epoch 80/100, Loss: 0.0045\n",
      "Epoch 90/100, Loss: 0.0028\n",
      "Epoch 100/100, Loss: 0.0053\n",
      "\n",
      "Elapsed time: 8.46 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_data_loader.dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print()\n",
    "et = (end - start) / 60\n",
    "print(f\"Elapsed time: {et:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13cb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 71.79%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_accuracy = correct / total\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57f5ee",
   "metadata": {},
   "source": [
    "#### 2. __Fine Tune Entire Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d30598",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6670e86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes) # modify output neurons\n",
    "model.cuda() # send model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdbec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3224\n",
      "Epoch 20/100, Loss: 0.1184\n",
      "Epoch 30/100, Loss: 0.0490\n",
      "Epoch 40/100, Loss: 0.0229\n",
      "Epoch 50/100, Loss: 0.0147\n",
      "Epoch 60/100, Loss: 0.0079\n",
      "Epoch 70/100, Loss: 0.0033\n",
      "Epoch 80/100, Loss: 0.0023\n",
      "Epoch 90/100, Loss: 0.0023\n",
      "Epoch 100/100, Loss: 0.0022\n",
      "\n",
      "Elapsed time: 11.42 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_data_loader.dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print()\n",
    "et = (end - start) / 60\n",
    "print(f\"Elapsed time: {et:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf79ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 69.23%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_accuracy = correct / total\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3556a",
   "metadata": {},
   "source": [
    "#### 3. __Hybrid Fine Tuning__ - Freeze First 10 Layers & Unfreeze the Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25961ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "counter = 0\n",
    "for child in model.children():\n",
    "    counter += 1\n",
    "    if counter == 1:\n",
    "        continue \n",
    "    if counter < 11: \n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False # freezing only the first 10 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afff9c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes) # modify output neurons\n",
    "model.cuda() # send model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ab5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.7189\n",
      "Epoch 20/100, Loss: 0.7376\n",
      "Epoch 30/100, Loss: 0.7352\n",
      "Epoch 40/100, Loss: 0.7296\n",
      "Epoch 50/100, Loss: 0.7129\n",
      "Epoch 60/100, Loss: 0.7503\n",
      "Epoch 70/100, Loss: 0.7691\n",
      "Epoch 80/100, Loss: 0.7189\n",
      "Epoch 90/100, Loss: 0.7229\n",
      "Epoch 100/100, Loss: 0.7200\n",
      "\n",
      "Elapsed time: 11.51 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_data_loader.dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print()\n",
    "et = (end - start) / 60\n",
    "print(f\"Elapsed time: {et:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b3e906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 48.72%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_accuracy = correct / total\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a134958",
   "metadata": {},
   "source": [
    "#### __Concluding points__\n",
    "- Validation accuracy for fine tuning only the fully connected layers of VGG16 came out to be `71.79%`, trained in `8 minutes & 28 seconds`.<br><br>\n",
    "- Validation accuracy for fine tuning all of VGG16 came out to be `69.23%`, trained in `11 minutes & 25 seconds`.<br><br>\n",
    "- Validation accuracy for fine tuning all of VGG16 excet the first 10 layers came out to be `48.72%`, trained in `11 minutes & 30 seconds`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4e093",
   "metadata": {},
   "source": [
    "The above results suggests that fine tuning the fully connected layers alone is sufficient to get a good accuracy. Moreover, the training time is also least in this case. The accuracy decline when training more layers could be attributed to overparameterization, where too many parameters are being fine-tuned relative to the limited amount of training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
